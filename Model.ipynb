{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e7a4a3-25cc-49ad-8a66-bc9f16d61416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf88010-81da-4cda-bcbb-b1618256d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "raw_dir=r'mrlEyes_2018_01'\n",
    "for dirpath, dirname, filenames in os.walk(raw_dir):\n",
    "   for i  in [f for f in filenames if f.endswith('.png')]:\n",
    "     if i.split('_')[4]=='0':\n",
    "       shutil.copy(src=dirpath+'/'+i, dst=r'closed_eyes')\n",
    "     elif i.split('_')[4]=='1':\n",
    "      shutil.copy(src=dirpath+'/'+i, dst=r'open_eyes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e498061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in closed_eyes: 41946\n",
      "Number of images in open_eyes: 42952\n"
     ]
    }
   ],
   "source": [
    "closed_dir = 'closed_eyes'\n",
    "open_dir = 'open_eyes'\n",
    "\n",
    "# Count the number of images in closed and open directories\n",
    "def count_images(directory):\n",
    "    total_images = sum(len(files) for _, _, files in os.walk(directory))\n",
    "    return total_images\n",
    "\n",
    "closed_count = count_images(closed_dir)\n",
    "open_count = count_images(open_dir)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of images in closed_eyes:\", closed_count)\n",
    "print(\"Number of images in open_eyes:\", open_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb2fa3e-ac0c-4ab2-b0f7-fe4d3deb9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f9c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "source_closed = 'C:\\\\Users\\\\samik\\\\pythonlab\\\\Scripts\\\\Drowsinessdetection\\\\closed_eyes'\n",
    "source_open = 'C:\\\\Users\\\\samik\\\\pythonlab\\\\Scripts\\\\Drowsinessdetection\\\\open_eyes'\n",
    "train_dir = 'C:\\\\Users\\\\samik\\\\pythonlab\\\\Scripts\\\\Drowsinessdetection\\\\train_data'\n",
    "test_dir = 'C:\\\\Users\\\\samik\\\\pythonlab\\\\Scripts\\\\Drowsinessdetection\\\\test_data'\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy files from source to destination\n",
    "def copy_files(source, destination, file_list):\n",
    "    for file in file_list:\n",
    "        file_name = file\n",
    "        dest_file_path = os.path.join(destination, file_name)\n",
    "        # Check if the file already exists in the destination directory\n",
    "        if os.path.exists(dest_file_path):\n",
    "            # If the file exists, generate a new unique file name\n",
    "            file_name, file_extension = os.path.splitext(file)\n",
    "            counter = 1\n",
    "            while os.path.exists(os.path.join(destination, f\"{file_name}_{counter}{file_extension}\")):\n",
    "                counter += 1\n",
    "            file_name = f\"{file_name}_{counter}{file_extension}\"\n",
    "        shutil.copy(os.path.join(source, file), os.path.join(destination, file_name))\n",
    "\n",
    "\n",
    "# List all files in the closed and open eyes directories\n",
    "closed_files = os.listdir(source_closed)\n",
    "open_files = os.listdir(source_open)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(closed_files)\n",
    "random.shuffle(open_files)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_closed = closed_files[:int(0.8*len(closed_files))]\n",
    "train_open = open_files[:int(0.8*len(open_files))]\n",
    "test_closed = closed_files[int(0.8*len(closed_files)):]\n",
    "test_open = open_files[int(0.8*len(open_files)):]\n",
    "\n",
    "# Copy files to train directory\n",
    "copy_files(source_closed, os.path.join(train_dir, 'closed_eyes'), train_closed)\n",
    "copy_files(source_open, os.path.join(train_dir, 'open_eyes'), train_open)\n",
    "\n",
    "# Copy files to test directory\n",
    "copy_files(source_closed, os.path.join(test_dir, 'closed_eyes'), test_closed)\n",
    "copy_files(source_open, os.path.join(test_dir, 'open_eyes'), test_open)\n",
    "\n",
    "# Now you can use the generators as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9bb82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of closed eye images in train: 33556\n",
      "Number of open eye images in train: 34361\n",
      "Number of closed eye images in test: 8390\n",
      "Number of open eye images in test: 8591\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images in train and test directories\n",
    "def count_images(directory):\n",
    "    total_images = sum(len(files) for _, _, files in os.walk(directory))\n",
    "    return total_images\n",
    "\n",
    "train_closed_count = count_images(os.path.join(train_dir, 'closed_eyes'))\n",
    "train_open_count = count_images(os.path.join(train_dir, 'open_eyes'))\n",
    "test_closed_count = count_images(os.path.join(test_dir, 'closed_eyes'))\n",
    "test_open_count = count_images(os.path.join(test_dir, 'open_eyes'))\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of closed eye images in train:\", train_closed_count)\n",
    "print(\"Number of open eye images in train:\", train_open_count)\n",
    "print(\"Number of closed eye images in test:\", test_closed_count)\n",
    "print(\"Number of open eye images in test:\", test_open_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91788993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54334 images belonging to 2 classes.\n",
      "Found 13583 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the ImageDataGenerator for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    validation_split=0.2  # Splitting the data into training and validation\n",
    ")\n",
    "\n",
    "# Load training data from directory\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\samik\\pythonlab\\Scripts\\Drowsinessdetection\\train_data',\n",
    "    target_size=(80, 80),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use the training subset\n",
    ")\n",
    "\n",
    "# Load validation data from directory\n",
    "validation_data = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\samik\\pythonlab\\Scripts\\Drowsinessdetection\\train_data',\n",
    "    target_size=(80, 80),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use the validation subset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2208a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16981 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load test data from directory\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\samik\\pythonlab\\Scripts\\Drowsinessdetection\\test_data',\n",
    "    target_size=(80, 80),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6430a2ba-285a-4740-975d-bfd3a002aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model= InceptionV3(include_top=False,weights='imagenet',input_tensor=Input(shape=(80,80,3)))\n",
    "head_model=base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3147cf74-f0a3-4069-a7ad-002cace68049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "checkpoint=ModelCheckpoint(r'model checkpoint\\model.h5',monitor='val_loss',save_best_only=True,verbose=3)\n",
    "\n",
    "earlystop=EarlyStopping(monitor='val_loss',patience=7,verbose=3,restore_best_weights=True)\n",
    "learning_rate=ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=3)\n",
    "callbacks=[checkpoint,earlystop,learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c6ad1-767e-4d93-b016-4db7c862e03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a354e84-b7a9-4ed3-83a3-c08278875186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 3.8 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     -------------------------------------- 302.2/302.2 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "     ---------------------------------------- 46.2/46.2 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\samik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc7cebf-b7c7-4f82-8cfb-81a04e898d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model=Flatten()(head_model)\n",
    "head_model=Dense(64,activation='relu')(head_model)\n",
    "head_model=Dropout(0.5)(head_model)\n",
    "head_model=Dense(2,activation='softmax')(head_model)\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=head_model)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84588c8b-8f0b-4801-be27-6246138a26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\samik\\pythonlab\\lib\\site-packages (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samik\\pythonlab\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\samik\\pythonlab\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\samik\\pythonlab\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035d5b1f-1f1f-4240-b986-0e3ca1800fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526e4c26-3fce-487e-a5d3-fbc03bb2ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samik\\AppData\\Local\\Temp\\ipykernel_10604\\2631058467.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_data,steps_per_epoch=train_data.samples//batchsize,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.8818\n",
      "Epoch 1: val_loss improved from inf to 0.34336, saving model to model checkpoint\\model.h5\n",
      "679/679 [==============================] - 235s 337ms/step - loss: 0.3483 - accuracy: 0.8818 - val_loss: 0.3434 - val_accuracy: 0.8676 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.9105\n",
      "Epoch 2: val_loss improved from 0.34336 to 0.28717, saving model to model checkpoint\\model.h5\n",
      "679/679 [==============================] - 306s 450ms/step - loss: 0.2634 - accuracy: 0.9105 - val_loss: 0.2872 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9157\n",
      "Epoch 3: val_loss did not improve from 0.28717\n",
      "679/679 [==============================] - 274s 404ms/step - loss: 0.2452 - accuracy: 0.9157 - val_loss: 0.2943 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.9212\n",
      "Epoch 4: val_loss improved from 0.28717 to 0.27037, saving model to model checkpoint\\model.h5\n",
      "679/679 [==============================] - 273s 403ms/step - loss: 0.2358 - accuracy: 0.9212 - val_loss: 0.2704 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "679/679 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9214\n",
      "Epoch 5: val_loss did not improve from 0.27037\n",
      "679/679 [==============================] - 237s 349ms/step - loss: 0.2252 - accuracy: 0.9214 - val_loss: 0.3115 - val_accuracy: 0.8824 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd3ba45ff0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "batchsize=80\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit_generator(train_data,steps_per_epoch=train_data.samples//batchsize,\n",
    "                   validation_data=validation_data,\n",
    "                   validation_steps=validation_data.samples//batchsize,\n",
    "                   callbacks=callbacks,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d5ff490-af2e-46fc-9f8c-88ca9b6c36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792/6792 [==============================] - 1669s 246ms/step - loss: 0.1954 - accuracy: 0.9282\n",
      "0.19544434547424316\n",
      "0.9281665086746216\n"
     ]
    }
   ],
   "source": [
    "acc_tr,loss_tr=model.evaluate(train_data)\n",
    "print(acc_tr)\n",
    "print(loss_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "076190cd-9d69-4c58-aa68-5dab0e4bbdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samik\\AppData\\Local\\Temp\\ipykernel_10604\\4184188003.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  acc_vr,loss_vr=model.evaluate_generator(validation_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2764436602592468\n",
      "0.8936906456947327\n"
     ]
    }
   ],
   "source": [
    "acc_vr,loss_vr=model.evaluate_generator(validation_data)\n",
    "print(acc_vr)\n",
    "print(loss_vr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9479db0-9511-49bc-b78c-afaad4fc2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samik\\AppData\\Local\\Temp\\ipykernel_10604\\3010557615.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  acc_te,loss_te=model.evaluate_generator(test_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2028217613697052\n",
      "0.9274483323097229\n"
     ]
    }
   ],
   "source": [
    "acc_te,loss_te=model.evaluate_generator(test_data)\n",
    "print(acc_te)\n",
    "print(loss_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491a141-c199-41e5-8033-90c59e8d396b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
